import numpy as np
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

def fitness_function(X, y, selected_features):
    X_selected = X[:, selected_features == 1]
    model = SVC()
    model.fit(X_selected, y)
    accuracy = accuracy_score(y, model.predict(X_selected))
    feature_count = np.sum(selected_features)  # Size of the feature subset
    penalty = 0.1 * feature_count  # Penalize large feature sets
    return accuracy - penalty  # Combine accuracy and feature count

def crossover(parent1, parent2, pc):
    if np.random.rand() < pc:
        crossover_point = np.random.randint(1, len(parent1))
        child1 = np.concatenate([parent1[:crossover_point], parent2[crossover_point:]])
        child2 = np.concatenate([parent2[:crossover_point], parent1[crossover_point:]])
        return child1, child2
    else:
        return parent1.copy(), parent2.copy()

def mutation(child, pm):
    if np.random.rand() < pm:
        mutation_point = np.random.randint(len(child))
        child[mutation_point] = 1 - child[mutation_point]  # Flip the bit
    return child

def genetic_algorithm(X, y, P, G, pc, pm):
    population = np.random.randint(2, size=(P, X.shape[1]))  # Random binary strings
    for generation in range(G):
        fitness_scores = np.array([fitness_function(X, y, individual) for individual in population])
        
        # Select top-performing chromosomes (roulette wheel selection or tournament selection)
        selected_indices = np.argsort(fitness_scores)[-P//2:]  # Select the best half
        selected_population = population[selected_indices]
        
        # Crossover and mutation
        next_generation = []
        for i in range(0, P//2, 2):
            parent1, parent2 = selected_population[i], selected_population[i+1]
            child1, child2 = crossover(parent1, parent2, pc)
            next_generation.append(mutation(child1, pm))
            next_generation.append(mutation(child2, pm))
        
        population = np.array(next_generation)
        
        # Evaluate the best chromosome
        best_chromosome = population[np.argmax(fitness_scores)]
        best_fitness = fitness_scores.max()
        
        print(f"Generation {generation}, Best Fitness: {best_fitness}")
        
    return best_chromosome

# Example usage
X = np.random.rand(100, 10)  # Example dataset with 100 samples and 10 features
y = np.random.randint(2, size=100)  # Binary classification labels

P = 50  # Population size
G = 100  # Number of generations
pc = 0.8  # Crossover probability
pm = 0.1  # Mutation probability

best_feature_subset = genetic_algorithm(X, y, P, G, pc, pm)
print("Best feature subset:", best_feature_subset)
